{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04-create-server-model.ipynb',\n",
       " '01-preprocessing.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '02-prototype.ipynb',\n",
       " '03-final-model.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \"\"\"Removing http link and non word character at the beginning\"\"\"\n",
    "    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', '', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = (re.sub(r'[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(path):\n",
    "    \"\"\"Load processed data and split in to train and test.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, pct):\n",
    "    train_rows = int(df.shape[0]*(1-pct))\n",
    "    x_train = df.loc[:train_rows, 'review_text'].values\n",
    "    y_train = df.loc[:train_rows, 'pruned_rating'].values\n",
    "    x_test = df.loc[train_rows:, 'review_text'].values\n",
    "    y_test = df.loc[train_rows:, 'pruned_rating'].values\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def version_by_date(path: str, extension: str):\n",
    "    \"\"\"Select the latest file form a dictionary.\n",
    "    :parameter\n",
    "        path: root path\n",
    "        extension: file extension\n",
    "    \"\"\"\n",
    "    file_pattern = \".\" + extension\n",
    "    dir_list = [\n",
    "        item.split(\"_\")[1] for item in os.listdir(path) if \"version\" in item\n",
    "    ]\n",
    "    versions = [dt.strptime(item.replace(file_pattern, \"\"), '%Y-%m-%d').date() for item in dir_list]\n",
    "    latest_version = \"version_{}.{}\".format(max(versions), extension)\n",
    "    return os.path.join(path, latest_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_data = version_by_date(\"../datalake/feed/\", \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_reader(latest_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(df, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['easily installed on my parlor guitar the oval shape helps retain the strap and looks kewl installation is not rocket science '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(doc, label):\n",
    "    tf_idf = TfidfVectorizer(\n",
    "        strip_accents=None,\n",
    "        lowercase=False,\n",
    "        preprocessor=None,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=None,\n",
    "        tokenizer=tokenizer\n",
    "\n",
    "    )\n",
    "    param_space = {\n",
    "        \"random_state\": 1,\n",
    "        \"solver\": 'liblinear',\n",
    "        \"C\": 100.0,\n",
    "        \"penalty\": 'l2',\n",
    "        \"n_jobs\":-1\n",
    "    }\n",
    "    pipe = Pipeline([\n",
    "        ('vect', tf_idf),\n",
    "        ('clf', LogisticRegression(**param_space))\n",
    "    ])\n",
    "    pipe.fit(doc, label)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataops/miniconda3/envs/emotion/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "classifier = trainer(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenizer at 0x7f1762b42320>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=100.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                                    random_state=1, solver='liblinear',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9669871117684344"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../modellake/temp/lr_classifier.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier, os.path.join(\"../modellake/temp/\", \"lr_classifier.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = joblib.load(os.path.join(\"../modellake/temp/\", \"lr_classifier.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9669871117684344"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([\"low quality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update 15 july 2013i still really love how these assist in quick tuning but man are they flimsy all of my other musician friends who also love this tuner s ability to grab the right pitch also have em ---> 1 ---> 1\n",
      "for any usable tones while playing live the best bet is to plug it into a tube power amp direct to mixer or running it through a solid state amp is very uninspiring i didn t like the recorded tones ei ---> 0 ---> 0\n",
      "this is a great capo clamps well and quickly the clamp handle is easy to reach and is not going to easily break aluminum not plastic i like it and it was well under the price of others  ---> 2 ---> 2\n",
      "this is a really solid table mic stand and you re not going to find a better price i looked the base is solid and heavy and the actual stand is a sturdy metal tube i liked the first one enough that i  ---> 2 ---> 2\n",
      "this seems to have been a rare case but still i had my ukulele on is and it snapped i m worried what might happen with a guitar or a bass ---> 0 ---> 0\n",
      "i like this cleaner it s gentle on my guitar finish and it doesn t smell bad either  ---> 2 ---> 2\n",
      "this is an update to my original review because i have now fully tested two of these capos i m truly surprised by all the good reviews here i m not sure how it s possible i ve already outlined below i ---> 0 ---> 0\n",
      "i was very disappointed when i tried this thing i bought it so that i could play along the songs that i have on my ipod but the guitar sounds really distorted don t thing i haven t tried changing the  ---> 1 ---> 1\n",
      "i ordered this from the amazon warehouse as a refurbished item it was properly packaged but the base was broken and poorly glued together the glue didn t hold so the clamping base separated from the s ---> 0 ---> 0\n",
      "they only fit if you have enough room in your strap button if not they will just pop right out i threw mine away  ---> 0 ---> 0\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(X_test[:10], y_test[:10]):\n",
    "    print(\"{} ---> {} ---> {}\".format(x[:200], classifier.predict([x])[0], y ) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader and Data Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def version_by_number(path):\n",
    "    \"\"\"Select the latest file form a dictionary.\n",
    "    :parameter\n",
    "        path: root path\n",
    "    \"\"\"\n",
    "    dir_list = [\n",
    "        item.split(\"_\")[1] for item in os.listdir(path) if \"model\" in item\n",
    "    ]\n",
    "    if len(dir_list) > 0:\n",
    "        versions = [int(item) for item in dir_list]\n",
    "        latest_version = \"model_{}\".format(max(versions))\n",
    "        return latest_version\n",
    "    else:\n",
    "        raise Exception(\"There is no model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saver(path, model):\n",
    "    files = [item for item in os.listdir(path) if item != \"temp\"]\n",
    "    try:\n",
    "        if len(files) > 0:\n",
    "            versions = [int(item.split(\"_\")[1]) for item in files]\n",
    "            new_version = \"model_{}\".format(max(versions) + 1)\n",
    "            file_path = os.path.join(model_lake, new_version)\n",
    "            os.mkdir(file_path)\n",
    "            joblib.dump(model, os.path.join(file_path, \"classifier.pkl\"))\n",
    "            print(\"Model Saved: \".format(file_path))\n",
    "        else:\n",
    "            file_path = os.path.join(model_lake, \"model_1\")\n",
    "            os.mkdir(file_path)\n",
    "            joblib.dump(model, os.path.join(file_path, \"classifier.pkl\"))\n",
    "    except Exception as e:\n",
    "        raise \"Error Occurs: {}\".format(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver(\"../modellake/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_1', 'temp']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../modellake/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(path, version=None):\n",
    "    if version:\n",
    "        model_path = os.path.join(path, \"model_\".format(version))\n",
    "        model = joblib.load(os.path.join(model_path, \"classifier.pkl\"))\n",
    "        return model\n",
    "    else:\n",
    "        latest_model = os.path.join(path, version_by_number(path))\n",
    "        model = joblib.load(os.path.join(latest_model, \"classifier.pkl\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = loader(\"../modellake/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-51e80f5ecbb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
